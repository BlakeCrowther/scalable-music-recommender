{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bf5bcf5a",
      "metadata": {},
      "source": [
        "# Preliminary EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "18fb49af",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Suppress native-hadoop warning\n",
        "!sed -i '$a\\# Add the line for suppressing the NativeCodeLoader warning \\nlog4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR,console' /$HADOOP_HOME/etc/hadoop/log4j.properties\n",
        "# Auto reload modules\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8f208016",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('/home/work')\n",
        "BASE_DIR = '/home/work'\n",
        "DATA_DIR = BASE_DIR + '/data'\n",
        "\n",
        "DATASET = '/processed/user_rating_balanced'\n",
        "TRAIN_DIR = DATA_DIR + DATASET + '/train'\n",
        "TEST_DIR = DATA_DIR + DATASET + '/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1e90f6a6",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import split, col, count, desc, min, max, log, abs, mean, stddev, row_number, rand\n",
        "from pyspark.sql.window import Window\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from data.utils.data_loader import load_file_from_hdfs\n",
        "\n",
        "from EDA.clean_data import cleaned_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4c710bdb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('spark.app.submitTime', '1717117718523')\n",
            "('spark.master', 'local[4]')\n",
            "('spark.app.id', 'local-1717117719346')\n",
            "('spark.executor.id', 'driver')\n",
            "('spark.driver.host', '693f94dcf7da')\n",
            "('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n",
            "('spark.driver.port', '34157')\n",
            "('spark.rdd.compress', 'True')\n",
            "('spark.serializer.objectStreamReset', '100')\n",
            "('spark.submit.pyFiles', '')\n",
            "('spark.submit.deployMode', 'client')\n",
            "('spark.app.name', 'MusicRecommender')\n",
            "('spark.app.startTime', '1717117718643')\n",
            "('spark.driver.memory', '14g')\n",
            "('spark.ui.showConsoleProgress', 'true')\n",
            "('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n"
          ]
        }
      ],
      "source": [
        "conf = pyspark.SparkConf()\n",
        "settings = conf.getAll()\n",
        "\n",
        "# Set Spark Settings\n",
        "conf = pyspark.SparkConf().setAll([\n",
        "('spark.master', 'local[4]'),\n",
        "('spark.app.name', 'MusicRecommender'),\n",
        "('spark.driver.memory','14g')])\n",
        "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
        "\n",
        "# Print the Spark Session settings\n",
        "settings = spark.sparkContext.getConf().getAll()\n",
        "for s in settings:\n",
        "    print(s)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "729d5443",
      "metadata": {},
      "source": [
        "Load choosen partition of song ratings, song attributes, and genre hierarchy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "77aa6440",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "song_ratings_train_file_path = \"/raw/train/train_2.txt\"\n",
        "song_ratings_train = load_file_from_hdfs(song_ratings_train_file_path)\n",
        "\n",
        "song_ratings_test_file_path = \"/raw/test/test_2.txt\"\n",
        "song_ratings_test = load_file_from_hdfs(song_ratings_test_file_path)\n",
        "\n",
        "song_ratings = song_ratings_train.union(song_ratings_test)\n",
        "\n",
        "song_attributes_file_path = \"song-attributes.txt\"\n",
        "song_attributes = load_file_from_hdfs(song_attributes_file_path)\n",
        "\n",
        "genre_hierarchy_file_path = \"genre-hierarchy.txt\"\n",
        "genre_hierarchy = load_file_from_hdfs(genre_hierarchy_file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c2d3232",
      "metadata": {},
      "source": [
        "Call cleaned_df function to get cleaned df from EDA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "fb03f524",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- user_id: integer (nullable = true)\n",
            " |-- song_id: integer (nullable = true)\n",
            " |-- rating: integer (nullable = true)\n",
            " |-- album_id: integer (nullable = true)\n",
            " |-- artist_id: integer (nullable = true)\n",
            " |-- genre_id: integer (nullable = true)\n",
            " |-- genre_name: string (nullable = true)\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
            "|summary|           user_id|          song_id|            rating|          album_id|         artist_id|          genre_id|       genre_name|\n",
            "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
            "|  count|          78909821|         78909821|          78909821|          78909821|          78909821|          78909821|         78909821|\n",
            "|   mean|499746.46840439545|68274.02707812504|3.1528440674070213|10361.592222392697|4776.0641216636395|16.666298850177345|             NULL|\n",
            "| stddev| 57936.75037674207|39459.18779033151|1.6030326088607252| 5906.090895444379| 2680.786813237493| 42.91624825455018|             NULL|\n",
            "|    min|            400000|                0|                 1|                 0|                 0|                 0|Adult Alternative|\n",
            "|    max|            599999|           136735|                 5|             20542|              9441|               215|            World|\n",
            "+-------+------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Null Columns in cleaned df: {'user_id': 0, 'song_id': 0, 'rating': 0, 'album_id': 0, 'artist_id': 0, 'genre_id': 0, 'genre_name': 0}\n"
          ]
        }
      ],
      "source": [
        "df = cleaned_df(song_ratings,song_attributes,genre_hierarchy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "151641cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "data": {
            "text/plain": [
              "78909821"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e1f29772",
      "metadata": {},
      "source": [
        "Get users' rating count to ensure balanced distribution of ratings per user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "01ccf624",
      "metadata": {},
      "outputs": [],
      "source": [
        "user_ratings_count = df.groupBy(\"user_id\").count()\n",
        "user_ratings_count = user_ratings_count.withColumnRenamed(\"count\", \"ratings_count\")\n",
        "# user_ratings_count.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4d33939",
      "metadata": {},
      "source": [
        "Min and max values of users are quite different. There must be some outliers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e0906cec",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 50:===================================================>    (12 + 1) / 13]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Minimum value: 30\n",
            "Maximum value: 131533\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "min_max_values = user_ratings_count.select(min(\"ratings_count\").alias(\"min_value\"), max(\"ratings_count\").alias(\"max_value\")).first()\n",
        "\n",
        "min_value = min_max_values[\"min_value\"]\n",
        "max_value = min_max_values[\"max_value\"]\n",
        "\n",
        "print(\"Minimum value:\", min_value)\n",
        "print(\"Maximum value:\", max_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "82cc5e5c",
      "metadata": {},
      "source": [
        "Distribution is extremely skewed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "698d41d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 58:===================================================>    (12 + 1) / 13]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of users: 200000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# data= user_ratings_count.toPandas()\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(data['ratings_count'], bins=30, edgecolor='black')\n",
        "# plt.title('Distribution of Rating Counts per User')\n",
        "# plt.xlabel('Number of Ratings')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.show()\n",
        "\n",
        "total_users = user_ratings_count.count()\n",
        "print(\"Total number of users:\", total_users)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "b20715cc",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "user_ratings_count[user_ratings_count['ratings_count'] == 0].count() # no zero\n",
        "user_ratings_count = user_ratings_count.withColumn('log_ratings_count', log(user_ratings_count['ratings_count']))  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "09a8da42",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "mean_log = user_ratings_count.select(mean(col(\"log_ratings_count\"))).collect()[0][0]\n",
        "stddev_log = user_ratings_count.select(stddev(col(\"log_ratings_count\"))).collect()[0][0]\n",
        "\n",
        "user_ratings_count = user_ratings_count.withColumn(\"z_score\", (col(\"log_ratings_count\") - mean_log) / stddev_log)\n",
        "user_ratings_count = user_ratings_count.withColumn(\"is_outlier\", abs(col(\"z_score\")) > 3) # threshold 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "07babbe7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_ratings_count_cleaned = user_ratings_count.filter(col(\"is_outlier\") == False)\n",
        "# print(\"Original DataFrame:\", user_ratings_count.count())\n",
        "# print(\"Cleaned DataFrame (without outliers):\", user_ratings_count_cleaned.count())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eed7449d",
      "metadata": {},
      "source": [
        "Still extremely skewed with large range of ratings count."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "45c840ed",
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_ratings_count_cleaned_data= user_ratings_count_cleaned.toPandas()\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(user_ratings_count_cleaned_data['ratings_count'], bins=30, edgecolor='black')\n",
        "# plt.title('New Distribution of Rating Counts per User')\n",
        "# plt.xlabel('Number of Ratings')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "00a93cb9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_ratings_count_cleaned_df = df.join(user_ratings_count_cleaned.select(\"user_id\"), on=\"user_id\", how=\"inner\")\n",
        "#user_ratings_count_cleaned_df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "fa585b0b",
      "metadata": {},
      "outputs": [],
      "source": [
        "# user_ratings_count_cleaned_df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b274ac55",
      "metadata": {},
      "source": [
        "Use IQR, lower bound, upper bound to remove outliers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "fc8fc0b3",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Upper bound: 328.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 101:============================>                            (2 + 2) / 4]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data count after downsampling outliers: 35003255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "quantiles = user_ratings_count.approxQuantile(\"ratings_count\", [0.25, 0.75], 0.05)\n",
        "Q1 = quantiles[0]\n",
        "Q3 = quantiles[1]\n",
        "# IQR = Q3 - Q1\n",
        "\n",
        "# lower_bound = Q1 - (1.5 * IQR)\n",
        "upper_bound = Q3\n",
        "print(\"Upper bound:\", upper_bound)\n",
        "\n",
        "filtered_below_upper_bound = user_ratings_count.filter(col(\"ratings_count\") < upper_bound)\n",
        "ratings_below_upper_bound = df.join(filtered_below_upper_bound, on=\"user_id\", how=\"inner\")\n",
        "users_above_upper_bound = user_ratings_count.filter(col(\"ratings_count\") > upper_bound)\n",
        "ratings_above_upper_bound = df.join(users_above_upper_bound, on=\"user_id\", how=\"inner\")\n",
        "\n",
        "# Shuffle user ratings above the upper bound\n",
        "ratings_with_random = ratings_above_upper_bound.withColumn(\"rand\", rand())\n",
        "window_spec = Window.partitionBy(\"user_id\").orderBy(\"rand\")\n",
        "\n",
        "# Sample ratings above the upper bound to match the number of ratings at the upper bound\n",
        "ratings_with_row_number = ratings_with_random.withColumn(\"row_number\", row_number().over(window_spec))\n",
        "resampled_ratings = ratings_with_row_number.filter(col(\"row_number\") <= upper_bound).drop(\"rand\", \"row_number\")\n",
        "\n",
        "filtered_df = ratings_below_upper_bound.union(resampled_ratings)\n",
        "\n",
        "print(\"Data count after downsampling outliers:\", filtered_df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "f2e3a113",
      "metadata": {},
      "outputs": [],
      "source": [
        "# filtered_df_data = filtered_df.select(\"user_id\", \"ratings_count\").toPandas()\n",
        "\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.hist(filtered_df_data['ratings_count'], bins=30, edgecolor='black')\n",
        "# plt.title('New Distribution of Rating Counts per User')\n",
        "# plt.xlabel('Number of Ratings')\n",
        "# plt.ylabel('Frequency')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "de91990f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------+------+\n",
            "|user_id|song_id|rating|\n",
            "+-------+-------+------+\n",
            "| 400001|  82451|     5|\n",
            "| 400001|  84589|     5|\n",
            "| 400001|  56660|     4|\n",
            "| 400001|  38174|     5|\n",
            "| 400001|  18878|     5|\n",
            "| 400001|  39847|     5|\n",
            "| 400001| 125351|     4|\n",
            "| 400001|  86910|     5|\n",
            "| 400001|   3723|     5|\n",
            "| 400001|  18663|     4|\n",
            "| 400001|  94003|     4|\n",
            "| 400001|  30670|     4|\n",
            "| 400001| 125173|     5|\n",
            "| 400001|  83028|     5|\n",
            "| 400001|  83509|     4|\n",
            "| 400001|  66132|     5|\n",
            "| 400001| 114859|     5|\n",
            "| 400001| 129487|     3|\n",
            "| 400001|  18936|     5|\n",
            "| 400001|  13843|     4|\n",
            "+-------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+-------+------+\n",
            "|user_id|song_id|rating|\n",
            "+-------+-------+------+\n",
            "| 400001|  30670|     4|\n",
            "| 400001|  13843|     4|\n",
            "| 400001|  59796|     5|\n",
            "| 400001|  86910|     5|\n",
            "| 400001|  38174|     5|\n",
            "| 400001| 117092|     5|\n",
            "| 400001|  66132|     5|\n",
            "| 400001| 116627|     5|\n",
            "| 400001| 114356|     4|\n",
            "| 400001| 105698|     5|\n",
            "| 400003| 129582|     5|\n",
            "| 400003|   7475|     5|\n",
            "| 400003|   3378|     4|\n",
            "| 400003|  62462|     3|\n",
            "| 400003|  57959|     4|\n",
            "| 400003| 126373|     4|\n",
            "| 400003|  46722|     5|\n",
            "| 400003|  31139|     5|\n",
            "| 400003| 102062|     4|\n",
            "| 400003|  33806|     5|\n",
            "+-------+-------+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data count: 33004575\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 181:>                                                        (0 + 4) / 5]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test data count: 1998680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Create train test split such that there is still at least 10 random ratings per user in the test set\n",
        "filtered_df = filtered_df.select(\"user_id\", \"song_id\", \"rating\")\n",
        "# Shuffle the data\n",
        "shuffled_df = filtered_df.orderBy(rand())\n",
        "\n",
        "# Assign row numbers within each user_id partition\n",
        "window = Window.partitionBy(\"user_id\").orderBy(rand())\n",
        "df = shuffled_df.withColumn(\"row_number\", row_number().over(window))\n",
        "\n",
        "train_df = df.filter(col(\"row_number\") > 10)\n",
        "test_df = df.filter(col(\"row_number\") <= 10)\n",
        "\n",
        "train_df = train_df.drop(\"row_number\")\n",
        "test_df = test_df.drop(\"row_number\")\n",
        "print(\"Train data count:\", train_df.count())\n",
        "print(\"Test data count:\", test_df.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "696475c7",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "# Make dirs if not exist\n",
        "!mkdir -p $TRAIN_DIR\n",
        "!mkdir -p $TEST_DIR\n",
        "\n",
        "# Save Train to local\n",
        "train_df = train_df.coalesce(1)\n",
        "test_df = test_df.coalesce(1)\n",
        "train_df.write.csv(f\"file://{TRAIN_DIR}/temp\", header=False, mode=\"overwrite\", sep=\"\\t\")\n",
        "test_df.write.csv(f\"file://{TEST_DIR}/temp\", header=False, mode=\"overwrite\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ad39e9d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Move to single file\n",
        "! rm -rf $TRAIN_DIR/train_0.txt\n",
        "! mv $TRAIN_DIR/temp/part-00000* $TRAIN_DIR/train_0.txt\n",
        "! rm -rf $TEST_DIR/test_0.txt\n",
        "! mv $TEST_DIR/temp/part-00000* $TEST_DIR/test_0.txt\n",
        "\n",
        "# Clean up\n",
        "! rm -rf $TRAIN_DIR/temp\n",
        "! rm -rf $TEST_DIR/temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37bcddc6",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b83c5cff",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
