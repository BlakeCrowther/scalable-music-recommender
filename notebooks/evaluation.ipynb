{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress native-hadoop warning\n",
    "!sed -i '$a\\# Add the line for suppressing the NativeCodeLoader warning \\nlog4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR,console' /$HADOOP_HOME/etc/hadoop/log4j.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/work')\n",
    "\n",
    "BASE_DIR = '/home/work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "from data.utils.data_loader import load_from_hdfs\n",
    "from models.utils import load_model\n",
    "from models.evaluation_metrics import calculate_rmse, calculate_mae, calculate_song_coverage, calculate_user_coverage, calculate_precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spark.driver.host', '6f6ec6ea2650')\n",
      "('spark.app.startTime', '1717093914712')\n",
      "('spark.master', 'local[10]')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.app.id', 'local-1717093915437')\n",
      "('spark.app.submitTime', '1717093914589')\n",
      "('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark.driver.port', '44215')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.submit.pyFiles', '')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.app.name', 'MusicRecommender')\n",
      "('spark.driver.memory', '14g')\n",
      "('spark.ui.showConsoleProgress', 'true')\n",
      "('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n"
     ]
    }
   ],
   "source": [
    "# Set Spark Settings\n",
    "conf = pyspark.SparkConf().setAll([\n",
    "    ('spark.master', 'local[10]'),\n",
    "    ('spark.app.name', 'MusicRecommender'),\n",
    "    ('spark.driver.memory','14g'),\n",
    "    # ('spark.sql.shuffle.partitions', '200'),\n",
    "])\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Print Spark Settings\n",
    "settings = spark.sparkContext.getConf().getAll()\n",
    "for s in settings:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24891408 training records and 6224643 test records from HDFS\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- song_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- album_id: integer (nullable = true)\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- genre_id: integer (nullable = true)\n",
      " |-- genre_name: string (nullable = true)\n",
      " |-- partition_id: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:>                                                       (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|song_id|rating|\n",
      "+-------+-------+------+\n",
      "+-------+-------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.0 = Relevant Recommendations: 0 / Total Recommendations: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 324:>                                                      (0 + 10) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.0 = Relevant Recommendations: 0 / Relevant Test Items: 6224643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Results DataFrame\n",
    "results = []\n",
    "model_dirs = ['als_model']\n",
    "model_types = ['ALS']\n",
    "datasets = ['processed/user_rating_balanced']\n",
    "partitions = [1]\n",
    "\n",
    "# Static Variables\n",
    "total_size = 717872016\n",
    "total_users = 1823179\n",
    "total_songs = 136736\n",
    "\n",
    "user_recs = None\n",
    "predictions = None\n",
    "\n",
    "batch_size = 10000\n",
    "n_recs = 50\n",
    "\n",
    "for model_dir, model_type in zip(model_dirs, model_types):\n",
    "    for dataset in datasets: \n",
    "        for par in partitions:            \n",
    "             # Clear Cache\n",
    "            spark.catalog.clearCache()\n",
    "            \n",
    "            # Load Data\n",
    "            train_data, test_data = load_from_hdfs(dataset, par)\n",
    "            \n",
    "            # Load Model\n",
    "            model_path = f'file://{BASE_DIR}/models/{model_dir}'\n",
    "            model = load_model(model_type, model_path)\n",
    "            \n",
    "            # Train Metrics\n",
    "            train_user_ids = train_data.select('user_id').distinct()\n",
    "            train_users = train_user_ids.count()\n",
    "            train_song_ids = train_data.select('song_id').distinct()\n",
    "            train_songs = train_song_ids.count()\n",
    "            \n",
    "            # Song Metrics\n",
    "            test_user_ids = test_data.select('user_id').distinct()\n",
    "            test_users = test_user_ids.count()\n",
    "            test_song_ids = test_data.select('song_id').distinct()\n",
    "            test_songs = test_song_ids.count()\n",
    "\n",
    "            # Recommendation Metrics\n",
    "            for i in range(0, test_users, batch_size):\n",
    "                start = i\n",
    "                end = i + batch_size\n",
    "                test_user_batch = \n",
    "                user_recs_batch = model.recommendForUserSubset(test_user_batch, 50)\n",
    "                if user_recs is None:\n",
    "                    user_recs = user_recs_batch\n",
    "                else:\n",
    "                    user_recs = user_recs.union(user_recs_batch)\n",
    "            \n",
    "            # Explode Recommendations\n",
    "            user_recs = user_recs.select('user_id', F.explode('recommendations').alias('recommendation'))\n",
    "            user_recs = user_recs.select('user_id', F.col('recommendation.song_id').alias('song_id'), F.col('recommendation.rating').alias('rating'))\n",
    "            user_recs.show(5)\n",
    "            \n",
    "            recommendation_users = user_recs.select('user_id').distinct().count()\n",
    "            recommendation_songs = user_recs.select('song_id').distinct().count()\n",
    "            \n",
    "                                    \n",
    "            # Coverage Metrics\n",
    "            test_song_coverage = calculate_song_coverage(train_songs, test_songs)\n",
    "            test_overall_song_coverage = calculate_song_coverage(total_songs, test_songs)\n",
    "            test_user_coverage = calculate_user_coverage(train_users, test_users)\n",
    "            test_overall_user_coverage = calculate_user_coverage(total_users, test_users)\n",
    "            recommendations_song_coverage = calculate_song_coverage(train_songs, recommendation_songs)\n",
    "            recommendations_overall_song_coverage = calculate_song_coverage(total_songs, recommendation_songs)\n",
    "            recommendations_user_coverage = calculate_user_coverage(train_users, recommendation_users)\n",
    "            recommendations_overall_user_coverage = calculate_user_coverage(total_users, recommendation_users)\n",
    "            \n",
    "            # Get Predictions\n",
    "            predictions = model.transform(test_data)\n",
    "            \n",
    "            # Evaluation Metrics\n",
    "            rmse = calculate_rmse(predictions)\n",
    "            mae = calculate_mae(predictions)\n",
    "            precision, recall = calculate_precision_recall(user_recs, test_data, 0.0)            \n",
    "            \n",
    "            results.append({\n",
    "                'Model': model_type,\n",
    "                'Dataset': dataset,\n",
    "                'Users(Train:Test)': f'{train_users} : {test_users}',\n",
    "                'Songs(Train:Test)': f'{train_songs} : {test_songs}',\n",
    "                'Test User Coverage(Model:Overall)': f'{round(test_user_coverage, 2)} : {round(test_overall_user_coverage, 2)}',\n",
    "                'Test Song Coverage(Model:Overall)': f'{round(test_song_coverage, 2)} : {round(test_overall_song_coverage, 2)}',\n",
    "                'Recommendations User Coverage(Model:Overall)': f'{round(recommendations_user_coverage, 2)} : {round(recommendations_overall_user_coverage, 2)}',\n",
    "                'Recommendations Song Coverage(Model:Overall)': f'{round(recommendations_song_coverage, 2)} : {round(recommendations_overall_song_coverage, 2)}',\n",
    "                'Recommendations Precision': round(precision, 4),\n",
    "                'Recommendations Recall': round(recall, 4),     \n",
    "                'Predictions RMSE': rmse,\n",
    "                'Predictions MAE': mae,\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------+-----------------+-----------------+---------------------------------+---------------------------------+--------------------------------------------+--------------------------------------------+-------------------------+----------------------+----------------+---------------+\n",
      "|Model|Dataset                       |Users(Train:Test)|Songs(Train:Test)|Test User Coverage(Model:Overall)|Test Song Coverage(Model:Overall)|Recommendations User Coverage(Model:Overall)|Recommendations Song Coverage(Model:Overall)|Recommendations Precision|Recommendations Recall|Predictions RMSE|Predictions MAE|\n",
      "+-----+------------------------------+-----------------+-----------------+---------------------------------+---------------------------------+--------------------------------------------+--------------------------------------------+-------------------------+----------------------+----------------+---------------+\n",
      "|ALS  |processed/user_rating_balanced|173463 : 173446  |136735 : 136267  |1.0 : 0.1                        |1.0 : 1.0                        |0.0 : 0.0                                   |0.0 : 0.0                                   |0.0                      |0.0                   |1.1318597       |0.89363813     |\n",
      "+-----+------------------------------+-----------------+-----------------+---------------------------------+---------------------------------+--------------------------------------------+--------------------------------------------+-------------------------+----------------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Results Schema\n",
    "schema = StructType([\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Dataset\", StringType(), True),\n",
    "    StructField(\"Users(Train:Test)\", StringType(), True),\n",
    "    StructField(\"Songs(Train:Test)\", StringType(), True),\n",
    "    StructField(\"Test User Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Test Song Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Recommendations User Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Recommendations Song Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Recommendations Precision\", FloatType(), True),\n",
    "    StructField(\"Recommendations Recall\", FloatType(), True),\n",
    "    StructField(\"Predictions RMSE\", FloatType(), True),\n",
    "    StructField(\"Predictions MAE\", FloatType(), True),\n",
    "])\n",
    "\n",
    "# Output Results as DF\n",
    "results_df = spark.createDataFrame(results, schema)\n",
    "results_df.show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
