{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress native-hadoop warning\n",
    "!sed -i '$a\\# Add the line for suppressing the NativeCodeLoader warning \\nlog4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR,console' /$HADOOP_HOME/etc/hadoop/log4j.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/work')\n",
    "\n",
    "BASE_DIR = '/home/work'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.recommendation import ALSModel\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "\n",
    "from data.utils.data_loader import load_from_hdfs\n",
    "from models.utils import load_model\n",
    "from models.evaluation_metrics import calculate_rmse, calculate_mae, calculate_song_coverage, calculate_user_coverage, calculate_precision_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spark.app.id', 'local-1717107183264')\n",
      "('spark.master', 'local[8]')\n",
      "('spark.app.startTime', '1717107182653')\n",
      "('spark.executor.id', 'driver')\n",
      "('spark.driver.host', '693f94dcf7da')\n",
      "('spark.driver.port', '34037')\n",
      "('spark.app.submitTime', '1717107182542')\n",
      "('spark.driver.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n",
      "('spark.rdd.compress', 'True')\n",
      "('spark.serializer.objectStreamReset', '100')\n",
      "('spark.submit.pyFiles', '')\n",
      "('spark.submit.deployMode', 'client')\n",
      "('spark.app.name', 'MusicRecommender')\n",
      "('spark.driver.memory', '14g')\n",
      "('spark.ui.showConsoleProgress', 'true')\n",
      "('spark.executor.extraJavaOptions', '-Djava.net.preferIPv6Addresses=false -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED -Djdk.reflect.useDirectMethodHandle=false')\n"
     ]
    }
   ],
   "source": [
    "# Set Spark Settings\n",
    "conf = pyspark.SparkConf().setAll([\n",
    "    ('spark.master', 'local[8]'),\n",
    "    ('spark.app.name', 'MusicRecommender'),\n",
    "    ('spark.driver.memory','14g'),\n",
    "    # ('spark.sql.shuffle.partitions', '200'),\n",
    "])\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "\n",
    "# Print Spark Settings\n",
    "settings = spark.sparkContext.getConf().getAll()\n",
    "for s in settings:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 29381421 training records and 1734630 test records from HDFS\n",
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- song_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      " |-- album_id: integer (nullable = true)\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- genre_id: integer (nullable = true)\n",
      " |-- genre_name: string (nullable = true)\n",
      " |-- partition_id: integer (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|user_id|    recommendation|\n",
      "+-------+------------------+\n",
      "| 400001| {54718, 6.300992}|\n",
      "| 400001| {52620, 6.180156}|\n",
      "| 400001| {73903, 6.074844}|\n",
      "| 400001|{113439, 6.027107}|\n",
      "| 400001| {45296, 5.859674}|\n",
      "+-------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|song_id|  rating|\n",
      "+-------+-------+--------+\n",
      "| 400001|  54718|6.300992|\n",
      "| 400001|  52620|6.180156|\n",
      "| 400001|  73903|6.074844|\n",
      "| 400001| 113439|6.027107|\n",
      "| 400001|  45296|5.859674|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.00015853524959213205 = Relevant Recommendations: 275 / Total Recommendations: 1734630\n",
      "Recall: 0.00015853524959213205 = Relevant Recommendations: 275 / Relevant Test Items: 1734630\n"
     ]
    }
   ],
   "source": [
    "# Results DataFrame\n",
    "results = []\n",
    "model_dirs = ['als_model']\n",
    "model_types = ['ALS']\n",
    "datasets = ['processed/user_rating_balanced']\n",
    "partitions = [1]\n",
    "\n",
    "# Static Variables\n",
    "total_size = 717872016\n",
    "total_users = 1823179\n",
    "total_songs = 136736\n",
    "\n",
    "user_recs = None\n",
    "predictions = None\n",
    "\n",
    "batch_size = 10000\n",
    "n_recs = 10\n",
    "\n",
    "for model_dir, model_type in zip(model_dirs, model_types):\n",
    "    for dataset in datasets: \n",
    "        for par in partitions:            \n",
    "             # Clear Cache\n",
    "            spark.catalog.clearCache()\n",
    "            \n",
    "            # Load Data\n",
    "            train_data, test_data = load_from_hdfs(dataset, par)\n",
    "            \n",
    "            # Load Model\n",
    "            model_path = f'file://{BASE_DIR}/models/{model_dir}'\n",
    "            model = load_model(model_type, model_path)\n",
    "            \n",
    "            # Train Metrics\n",
    "            train_user_ids = train_data.select('user_id').distinct()\n",
    "            train_users = train_user_ids.count()\n",
    "            train_song_ids = train_data.select('song_id').distinct()\n",
    "            train_songs = train_song_ids.count()\n",
    "            \n",
    "            # Song Metrics\n",
    "            test_user_ids = test_data.select('user_id').distinct()\n",
    "            test_users = test_user_ids.count()\n",
    "            test_song_ids = test_data.select('song_id').distinct()\n",
    "            test_songs = test_song_ids.count()\n",
    "\n",
    "            spark.catalog.clearCache()\n",
    "            \n",
    "            # Recommendation Metrics\n",
    "            user_recs = model.recommendForAllUsers(n_recs)\n",
    "            user_recs = user_recs.select('user_id', F.explode('recommendations').alias('recommendation'))\n",
    "            user_recs = user_recs.select('user_id', F.col('recommendation.song_id').alias('song_id'), F.col('recommendation.rating').alias('rating'))\n",
    "                        \n",
    "            recommendation_users = user_recs.select('user_id').distinct().count()\n",
    "            recommendation_songs = user_recs.select('song_id').distinct().count()\n",
    "            \n",
    "                                    \n",
    "            # Coverage Metrics\n",
    "            test_song_coverage = calculate_song_coverage(train_songs, test_songs)\n",
    "            test_overall_song_coverage = calculate_song_coverage(total_songs, test_songs)\n",
    "            test_user_coverage = calculate_user_coverage(train_users, test_users)\n",
    "            test_overall_user_coverage = calculate_user_coverage(total_users, test_users)\n",
    "            recommendations_song_coverage = calculate_song_coverage(train_songs, recommendation_songs)\n",
    "            recommendations_overall_song_coverage = calculate_song_coverage(total_songs, recommendation_songs)\n",
    "            recommendations_user_coverage = calculate_user_coverage(train_users, recommendation_users)\n",
    "            recommendations_overall_user_coverage = calculate_user_coverage(total_users, recommendation_users)\n",
    "            \n",
    "            # Get Predictions\n",
    "            predictions = model.transform(test_data)\n",
    "            \n",
    "            # Evaluation Metrics\n",
    "            rmse = calculate_rmse(predictions)\n",
    "            mae = calculate_mae(predictions)\n",
    "            precision, recall = calculate_precision_recall(user_recs, test_data, 0.0)            \n",
    "            \n",
    "            results.append({\n",
    "                'Model': model_type,\n",
    "                'Dataset': dataset,\n",
    "                'Users(Train:Test)': f'{train_users} : {test_users}',\n",
    "                'Songs(Train:Test)': f'{train_songs} : {test_songs}',\n",
    "                'Test User Coverage(Model:Overall)': f'{round(test_user_coverage, 2)} : {round(test_overall_user_coverage, 2)}',\n",
    "                'Test Song Coverage(Model:Overall)': f'{round(test_song_coverage, 2)} : {round(test_overall_song_coverage, 2)}',\n",
    "                'Recommendations User Coverage(Model:Overall)': f'{round(recommendations_user_coverage, 2)} : {round(recommendations_overall_user_coverage, 2)}',\n",
    "                'Recommendations Song Coverage(Model:Overall)': f'{round(recommendations_song_coverage, 2)} : {round(recommendations_overall_song_coverage, 2)}',\n",
    "                'Recommendations Precision': round(precision, 4),\n",
    "                'Recommendations Recall': round(recall, 4),     \n",
    "                'Predictions RMSE': rmse,\n",
    "                'Predictions MAE': mae,\n",
    "            })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------------------+-----------------+-----------------+---------------------------------+---------------------------------+--------------------------------------------+--------------------------------------------+-------------------------+----------------------+----------------+---------------+\n",
      "|Model|Dataset                       |Users(Train:Test)|Songs(Train:Test)|Test User Coverage(Model:Overall)|Test Song Coverage(Model:Overall)|Recommendations User Coverage(Model:Overall)|Recommendations Song Coverage(Model:Overall)|Recommendations Precision|Recommendations Recall|Predictions RMSE|Predictions MAE|\n",
      "+-----+------------------------------+-----------------+-----------------+---------------------------------+---------------------------------+--------------------------------------------+--------------------------------------------+-------------------------+----------------------+----------------+---------------+\n",
      "|ALS  |processed/user_rating_balanced|173463 : 173463  |136735 : 121149  |1.0 : 0.1                        |0.89 : 0.89                      |1.0 : 0.1                                   |0.09 : 0.09                                 |2.0E-4                   |2.0E-4                |1.0356511       |0.8115388      |\n",
      "+-----+------------------------------+-----------------+-----------------+---------------------------------+---------------------------------+--------------------------------------------+--------------------------------------------+-------------------------+----------------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluation Results Schema\n",
    "schema = StructType([\n",
    "    StructField(\"Model\", StringType(), True),\n",
    "    StructField(\"Dataset\", StringType(), True),\n",
    "    StructField(\"Users(Train:Test)\", StringType(), True),\n",
    "    StructField(\"Songs(Train:Test)\", StringType(), True),\n",
    "    StructField(\"Test User Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Test Song Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Recommendations User Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Recommendations Song Coverage(Model:Overall)\", StringType(), True),\n",
    "    StructField(\"Recommendations Precision\", FloatType(), True),\n",
    "    StructField(\"Recommendations Recall\", FloatType(), True),\n",
    "    StructField(\"Predictions RMSE\", FloatType(), True),\n",
    "    StructField(\"Predictions MAE\", FloatType(), True),\n",
    "])\n",
    "\n",
    "# Output Results as DF\n",
    "results_df = spark.createDataFrame(results, schema)\n",
    "results_df.show(truncate=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
