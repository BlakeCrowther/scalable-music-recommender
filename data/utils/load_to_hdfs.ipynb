{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress native-hadoop warning\n",
    "!sed -i '$a\\# Add the line for suppressing the NativeCodeLoader warning \\nlog4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR,console' /$HADOOP_HOME/etc/hadoop/log4j.properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.join(os.getcwd(), 'work')\n",
    "data_dir = os.path.join(base_dir, 'data')\n",
    "\n",
    "# Load a specified dataset to hdfs such as 'raw' or some other processed dataset. \n",
    "def load_to_hdfs(dataset):\n",
    "    train_test_dirs = [os.path.join(data_dir, dataset, 'train'), os.path.join(data_dir, dataset, 'test')]\n",
    "\n",
    "    # Load train and test data to hdfs\n",
    "    for path in train_test_dirs:\n",
    "        subprocess.run(['hdfs', 'dfs', '-mkdir', '-p', f'/data/{dataset}'])\n",
    "        subprocess.run(['hdfs', 'dfs', '-put', path, f'/data/{dataset}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'raw'\n",
    "load_to_hdfs(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Listing directories in HDFS\n",
      "drwxr-xr-x   - root supergroup          0 2024-05-15 15:07 /data\n",
      "drwxr-xr-x   - root supergroup          0 2024-05-15 15:08 /data/raw\n",
      "drwxr-xr-x   - root supergroup          0 2024-05-15 15:08 /data/raw/test\n",
      "-rw-r--r--   1 root supergroup   29250779 2024-05-15 15:08 /data/raw/test/test_0.txt\n",
      "-rw-r--r--   1 root supergroup   30361653 2024-05-15 15:08 /data/raw/test/test_1.txt\n",
      "-rw-r--r--   1 root supergroup   30360260 2024-05-15 15:08 /data/raw/test/test_2.txt\n",
      "-rw-r--r--   1 root supergroup   30360544 2024-05-15 15:08 /data/raw/test/test_3.txt\n",
      "-rw-r--r--   1 root supergroup   30360882 2024-05-15 15:08 /data/raw/test/test_4.txt\n",
      "-rw-r--r--   1 root supergroup   32362435 2024-05-15 15:08 /data/raw/test/test_5.txt\n",
      "-rw-r--r--   1 root supergroup   32362727 2024-05-15 15:08 /data/raw/test/test_6.txt\n",
      "-rw-r--r--   1 root supergroup   32360794 2024-05-15 15:08 /data/raw/test/test_7.txt\n",
      "-rw-r--r--   1 root supergroup   32360897 2024-05-15 15:08 /data/raw/test/test_8.txt\n",
      "-rw-r--r--   1 root supergroup    3750961 2024-05-15 15:08 /data/raw/test/test_9.txt\n",
      "drwxr-xr-x   - root supergroup          0 2024-05-15 15:08 /data/raw/train\n",
      "-rw-r--r--   1 root supergroup 1116948159 2024-05-15 15:08 /data/raw/train/train_0.txt\n",
      "-rw-r--r--   1 root supergroup 1165261648 2024-05-15 15:08 /data/raw/train/train_1.txt\n",
      "-rw-r--r--   1 root supergroup 1167807043 2024-05-15 15:08 /data/raw/train/train_2.txt\n",
      "-rw-r--r--   1 root supergroup 1168046738 2024-05-15 15:08 /data/raw/train/train_3.txt\n",
      "-rw-r--r--   1 root supergroup 1167900398 2024-05-15 15:07 /data/raw/train/train_4.txt\n",
      "-rw-r--r--   1 root supergroup 1243252130 2024-05-15 15:08 /data/raw/train/train_5.txt\n",
      "-rw-r--r--   1 root supergroup 1241075737 2024-05-15 15:07 /data/raw/train/train_6.txt\n",
      "-rw-r--r--   1 root supergroup 1241481728 2024-05-15 15:07 /data/raw/train/train_7.txt\n",
      "-rw-r--r--   1 root supergroup 1241984479 2024-05-15 15:07 /data/raw/train/train_8.txt\n",
      "-rw-r--r--   1 root supergroup  143179231 2024-05-15 15:07 /data/raw/train/train_9.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['hdfs', 'dfs', '-ls', '-R', '/'], returncode=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list directories in hdfs for users\n",
    "print(f'\\nListing directories in HDFS')\n",
    "# crawl all of hdfs and list all directories\n",
    "subprocess.run(['hdfs', 'dfs', '-ls', '-R', '/'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
